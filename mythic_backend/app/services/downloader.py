import asyncio
import httpx, logging, mimetypes, json
from pathlib import Path
from typing import List, Dict

log = logging.getLogger("downloader")


# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ —Å–±–æ—Ä —Å—Å—ã–ª–æ–∫ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
def _collect_urls(items: List[Dict]) -> List[str]:
    """–ò—â–µ–º displayUrl –∏ images –≤–æ –≤—Å–µ—Ö latestPosts, childPosts –∏ stories."""
    urls: list[str] = []

    def walk(post: Dict):
        if post.get("displayUrl"):
            urls.append(post["displayUrl"])
        urls.extend(post.get("images", []))
        for child in post.get("childPosts", []):
            walk(child)

    for root in items:
        for p in root.get("latestPosts", []):
            walk(p)
        
        # –°–æ–±–∏—Ä–∞–µ–º URL –∏–∑ —Å—Ç–æ—Ä–∏—Å–æ–≤
        for story in root.get("stories", []):
            if story.get("displayUrl"):
                urls.append(story["displayUrl"])
            # –ï—Å–ª–∏ –µ—Å—Ç—å –º–∞—Å—Å–∏–≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ —Å—Ç–æ—Ä–∏—Å–µ
            if story.get("images"):
                urls.extend(story["images"])
            # –ï—Å–ª–∏ –µ—Å—Ç—å –≤–∏–¥–µ–æ –ø—Ä–µ–≤—å—é –≤ —Å—Ç–æ—Ä–∏—Å–µ
            if story.get("videoUrl"):
                urls.append(story["videoUrl"])

        # –°–æ–±–∏—Ä–∞–µ–º URL –∏–∑ –∞–∫—Ç—É–∞–ª—å–Ω–æ–≥–æ (highlights)
        for highlight in root.get("highlights", []):
            # –ù–µ–∫–æ—Ç–æ—Ä—ã–µ —Å–∫—Ä–∏–ø—Ç–µ—Ä—ã –æ—Ç–¥–∞—é—Ç highlight.items
            for item in highlight.get("items", []):
                if item.get("displayUrl"):
                    urls.append(item["displayUrl"])
                if item.get("images"):
                    urls.extend(item["images"])
                if item.get("videoUrl"):
                    urls.append(item["videoUrl"])
            # –ù–∞ —Å–ª—É—á–∞–π –ø–ª–æ—Å–∫–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –±–µ–∑ items
            if highlight.get("displayUrl"):
                urls.append(highlight["displayUrl"])
            if highlight.get("images"):
                urls.extend(highlight["images"])
            if highlight.get("videoUrl"):
                urls.append(highlight["videoUrl"])

    # —É–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã, —Å–æ—Ö—Ä–∞–Ω—è—è –ø–æ—Ä—è–¥–æ–∫
    seen = set()
    out = []
    for u in urls:
        if u not in seen:
            out.append(u)
            seen.add(u)
    return out


# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ —Å retry –ª–æ–≥–∏–∫–æ–π ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
async def _save(url: str, folder: Path, client: httpx.AsyncClient, idx: int, max_retries: int = 3):
    """–°–∫–∞—á–∏–≤–∞–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å –ø–æ–≤—Ç–æ—Ä–Ω—ã–º–∏ –ø–æ–ø—ã—Ç–∫–∞–º–∏ –ø—Ä–∏ –æ—à–∏–±–∫–∞—Ö —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è"""
    for attempt in range(max_retries + 1):
        try:
            # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Ç–∞–π–º–∞—É—Ç –∏ –¥–æ–±–∞–≤–ª—è–µ–º –∑–∞–¥–µ—Ä–∂–∫—É –º–µ–∂–¥—É –ø–æ–ø—ã—Ç–∫–∞–º–∏
            timeout = httpx.Timeout(30.0, connect=10.0)
            r = await client.get(url, follow_redirects=True, timeout=timeout)
            r.raise_for_status()
            
            # –ø–æ–ª—É—á–∞–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ –ø–æ Content-Type, fallback = .jpg
            ext = mimetypes.guess_extension(r.headers.get("content-type", "")) or ".jpg"
            fname = folder / f"{idx:03d}{ext}"
            fname.write_bytes(r.content)
            log.debug("saved %s", fname.name)
            return  # –£—Å–ø–µ—à–Ω–æ —Å–∫–∞—á–∞–ª–∏, –≤—ã—Ö–æ–¥–∏–º
            
        except (httpx.ConnectError, httpx.TimeoutException, httpx.RequestError) as e:
            if attempt < max_retries:
                wait_time = 2 ** attempt  # –≠–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞
                log.warning(f"Attempt {attempt + 1} failed for {url}: {e}. Retrying in {wait_time}s...")
                await asyncio.sleep(wait_time)
            else:
                log.error(f"Failed to download {url} after {max_retries + 1} attempts: {e}")
                # –°–æ–∑–¥–∞–µ–º –∑–∞–≥–ª—É—à–∫—É –¥–ª—è –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–µ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
                _create_placeholder_image(folder, idx)
        except Exception as e:
            log.error(f"Unexpected error downloading {url}: {e}")
            _create_placeholder_image(folder, idx)
            return


def _create_placeholder_image(folder: Path, idx: int):
    """–°–æ–∑–¥–∞–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ-–∑–∞–≥–ª—É—à–∫—É –¥–ª—è –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏—Ö —Ñ–∞–π–ª–æ–≤"""
    try:
        from PIL import Image, ImageDraw, ImageFont
        
        # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ—Å—Ç–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ-–∑–∞–≥–ª—É—à–∫—É
        img = Image.new('RGB', (400, 300), color='#f0f0f0')
        draw = ImageDraw.Draw(img)
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ–∫—Å—Ç
        try:
            font = ImageFont.truetype("/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf", 24)
        except:
            font = ImageFont.load_default()
        
        text = f"Image {idx}\nNot Available"
        bbox = draw.textbbox((0, 0), text, font=font)
        text_width = bbox[2] - bbox[0]
        text_height = bbox[3] - bbox[1]
        
        x = (400 - text_width) // 2
        y = (300 - text_height) // 2
        draw.text((x, y), text, fill='#666666', font=font, align='center')
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∑–∞–≥–ª—É—à–∫—É
        fname = folder / f"{idx:03d}_placeholder.jpg"
        img.save(fname, format='JPEG', quality=80)
        log.info(f"Created placeholder image: {fname.name}")
        
    except Exception as e:
        log.error(f"Failed to create placeholder image: {e}")


async def _run_ocr_on_images(folder: Path):
    """–ó–∞–ø—É—Å–∫–∞–µ—Ç OCR –Ω–∞ –≤—Å–µ—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è—Ö –≤ –ø–∞–ø–∫–µ –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã"""
    try:
        from app.services.ocr_service import extract_text_from_images
        
        # –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (–∏—Å–∫–ª—é—á–∞—è placeholder'—ã)
        image_files = [
            f for f in folder.glob("*.jpg") 
            if not f.name.endswith("_placeholder.jpg")
        ]
        image_files.extend([f for f in folder.glob("*.jpeg") if not f.name.endswith("_placeholder.jpeg")])
        image_files.extend([f for f in folder.glob("*.png") if not f.name.endswith("_placeholder.png")])
        
        if not image_files:
            log.warning(f"No images found in {folder} for OCR")
            return
        
        log.info(f"üîç Starting OCR for {len(image_files)} images in {folder}")
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º OCR
        ocr_results = await extract_text_from_images(image_files)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        ocr_file = folder / "ocr_results.json"
        ocr_file.write_text(
            json.dumps(ocr_results, ensure_ascii=False, indent=2),
            encoding="utf-8"
        )
        
        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        images_with_text = sum(1 for r in ocr_results.values() if r.get("has_text"))
        log.info(f"‚úÖ OCR completed: {images_with_text}/{len(image_files)} images contain text")
        
    except Exception as e:
        log.error(f"‚ùå Error during OCR processing: {e}")


def download_photos(items: List[Dict], folder: Path):
    """–°–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –æ–±—ë—Ä—Ç–∫–∞ –¥–ª—è Starlette BackgroundTask —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫."""
    try:
        urls = _collect_urls(items)
        if not urls:
            log.warning("no image urls found ‚Äî nothing to download")
            return

        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–æ –ø–µ—Ä–≤—ã—Ö 15 —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–π –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
        urls = urls[:15]
        log.info("limiting to first %s images for optimal performance", len(urls))

        folder.mkdir(parents=True, exist_ok=True)
        log.info("downloading %s images ‚Üí %s", len(urls), folder)

        async def main():
            # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –∫–ª–∏–µ–Ω—Ç–∞ —Å –±–æ–ª–µ–µ –Ω–∞–¥–µ–∂–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
            limits = httpx.Limits(max_keepalive_connections=5, max_connections=10)
            timeout = httpx.Timeout(30.0, connect=10.0)
            
            async with httpx.AsyncClient(limits=limits, timeout=timeout) as client:
                # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –∑–∞–≥—Ä—É–∑–æ–∫
                semaphore = asyncio.Semaphore(3)
                
                async def download_with_semaphore(url: str, idx: int):
                    async with semaphore:
                        await _save(url, folder, client, idx)
                
                tasks = [download_with_semaphore(u, i) for i, u in enumerate(urls, 1)]
                await asyncio.gather(*tasks, return_exceptions=True)
            
            # –ü–æ—Å–ª–µ –∑–∞–≥—Ä—É–∑–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∑–∞–ø—É—Å–∫–∞–µ–º OCR
            log.info("üì∏ Images downloaded, starting OCR processing...")
            await _run_ocr_on_images(folder)

        
        try:
            loop = asyncio.get_running_loop()
            future = asyncio.run_coroutine_threadsafe(main(), loop)
            future.result(timeout=180)  # –£–≤–µ–ª–∏—á–∏–ª–∏ —Ç–∞–π–º–∞—É—Ç –¥–ª—è OCR
        except RuntimeError:
            asyncio.run(main())
            
        log.info("download and OCR completed (%s urls processed)", len(urls))
        
    except Exception as e:
        log.error(f"Critical error in download_photos: {e}")
        try:
            folder.mkdir(parents=True, exist_ok=True)
            _create_placeholder_image(folder, 1)
        except Exception as fallback_error:
            log.error(f"Failed to create fallback image: {fallback_error}")
