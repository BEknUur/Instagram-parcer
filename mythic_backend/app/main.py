# app/main.py
from fastapi import FastAPI, HTTPException, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import FileResponse
from pathlib import Path

import asyncio
from pydantic import AnyUrl
import json, logging, datetime

from app.config import settings
from app.services.apify_client import run_actor, fetch_run, fetch_items
from app.services.downloader import download_photos

log = logging.getLogger("api")
app = FastAPI(
    title="Mythic Instagram Parser API",
    description="–ü–∞—Ä—Å–∏–Ω–≥ –ø—Ä–æ—Ñ–∏–ª–µ–π Instagram: –ø–æ—Å—Ç—ã —Å —Ç–µ–∫—Å—Ç–∞–º–∏ –∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏.",
    version="1.0.0"
)

# –î–æ–±–∞–≤–ª—è–µ–º CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=[
        "http://localhost:5174",
        "http://localhost:3000",
        "http://104.248.18.254",
        "https://mythicai.me",
        "https://www.mythicai.me"
    ],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

@app.get("/health")
def health_check():
    return {"status": "ok", "service": "instagram-parser", "version": "1.0.0"}


@app.get("/start-scrape")
async def start_scrape(
    url: AnyUrl,
    username: str,
    background_tasks: BackgroundTasks
):
    """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ Instagram –ø—Ä–æ—Ñ–∏–ª—è —Å –±—ã—Å—Ç—Ä–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è"""
    clean_url = str(url).rstrip("/")
    user_identifier = f"user_{username.lower()}"

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤–∞–ª–∏–¥–Ω–æ—Å—Ç–∏ URL
    if not clean_url.startswith('https://www.instagram.com/'):
        raise HTTPException(400, "URL –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Å instagram.com")

    try:
        run_input = {
            "directUrls":     [clean_url],
            "resultsType":    "posts",
            "resultsLimit": 50,
            "searchLimit": 1,              # –¢–æ–ª—å–∫–æ –æ–¥–∏–Ω –ø—Ä–æ—Ñ–∏–ª—å
            "searchType": "user",
        }

        # –ó–∞–ø—É—Å–∫–∞–µ–º –∞–∫—Ç–æ—Ä –ë–ï–ó webhook - –±—É–¥–µ–º –∂–¥–∞—Ç—å –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è
        run = await run_actor(run_input)
        run_id = run["id"]

        log.info(f"üöÄ –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ –Ω–∞—á–∞—Ç –¥–ª—è {username}, runId={run_id}")

        # –ñ–¥–µ–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –∞–∫—Ç–æ—Ä–∞ (–º–∞–∫—Å–∏–º—É–º 3 –º–∏–Ω—É—Ç—ã –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –æ—Ç–∫–ª–∏–∫–∞)
        max_wait_time = 180  # 3 –º–∏–Ω—É—Ç—ã (—É–º–µ–Ω—å—à–∏–ª–∏ –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –æ—Ç–∫–ª–∏–∫–∞)
        check_interval = 3   # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∂–¥—ã–µ 3 —Å–µ–∫—É–Ω–¥—ã
        elapsed_time = 0

        while elapsed_time < max_wait_time:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞—Ç—É—Å –∞–∫—Ç–æ—Ä–∞
            run_status = await fetch_run(run_id)
            status = run_status.get("status")

            log.info(f"‚è≥ –°—Ç–∞—Ç—É—Å –ø–∞—Ä—Å–∏–Ω–≥–∞ {run_id}: {status} (–ø—Ä–æ—à–ª–æ {elapsed_time}—Å)")

            if status == "SUCCEEDED":
                # –ê–∫—Ç–æ—Ä –∑–∞–≤–µ—Ä—à–∏–ª—Å—è —É—Å–ø–µ—à–Ω–æ - –ø–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ
                dataset_id = run_status.get("defaultDatasetId")
                if not dataset_id:
                    raise HTTPException(500, "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å dataset_id")

                # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ
                items = await fetch_items(dataset_id, limit=run_input["resultsLimit"])

                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ –ª–æ–∫–∞–ª—å–Ω–æ
                run_dir = Path("data") / run_id
                run_dir.mkdir(parents=True, exist_ok=True)
                log.info(f"üìÅ –°–æ–∑–¥–∞–Ω–∞ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: {run_dir.absolute()}")

                user_meta = {
                    "user_id": user_identifier,
                    "username": username,
                    "instagram_url": clean_url,
                    "created_at": datetime.datetime.now().isoformat(),
                    "async_request": True,
                    "status": "data_ready"
                }
                (run_dir / "user_meta.json").write_text(json.dumps(user_meta, ensure_ascii=False, indent=2), encoding="utf-8")
                (run_dir / "posts.json").write_text(json.dumps(items, ensure_ascii=False, indent=2), encoding="utf-8")
                log.info(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω—ã user_meta.json –∏ posts.json ({len(items)} —ç–ª–µ–º–µ–Ω—Ç–æ–≤)")

                # –ó–∞–ø—É—Å–∫–∞–µ–º –∑–∞–≥—Ä—É–∑–∫—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ —Ñ–æ–Ω–µ (–ø–æ–ª–Ω–æ—Å—Ç—å—é –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ)
                images_dir = run_dir / "images"
                log.info(f"üöÄ –ó–∞–ø—É—Å–∫ –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–π –∑–∞–≥—Ä—É–∑–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ {images_dir}")
                background_tasks.add_task(download_photos_async, items, images_dir, run_id, username)

                log.info(f"‚úÖ –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω –¥–ª—è {username}. –ü–æ–ª—É—á–µ–Ω–æ {len(items)} —ç–ª–µ–º–µ–Ω—Ç–æ–≤.")

                # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—Ç–≤–µ—Ç –∫–ª–∏–µ–Ω—Ç—É –°–†–ê–ó–£ (–±–µ–∑ –æ–∂–∏–¥–∞–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π)
                return {
                    "success": True,
                    "runId": run_id,
                    "username": username,
                    "url": clean_url,
                    "message": f"‚úÖ –ü–∞—Ä—Å–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω! –ü–æ–ª—É—á–µ–Ω–æ {len(items)} —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –¥–∞–Ω–Ω—ã—Ö. –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∑–∞–≥—Ä—É–∂–∞—é—Ç—Å—è –≤ —Ñ–æ–Ω–µ.",
                    "data": items,
                    "status": "data_ready",
                    "stats": {
                        "total_items": len(items),
                        "profile_data": len([item for item in items if item.get("username")]),
                        "processing_time_seconds": elapsed_time,
                        "images_status": "loading"
                    }
                }

            elif status == "FAILED":
                raise HTTPException(500, f"–ü–∞—Ä—Å–∏–Ω–≥ –Ω–µ —É–¥–∞–ª—Å—è: {run_status.get('statusMessage', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞')}")

            elif status in ["RUNNING", "READY"]:
                # –î–ª—è –ø–µ—Ä–≤—ã—Ö 30 —Å–µ–∫—É–Ω–¥ –∂–¥–µ–º –Ω–æ—Ä–º–∞–ª—å–Ω–æ–≥–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è
                if elapsed_time < 30:
                    await asyncio.sleep(check_interval)
                    elapsed_time += check_interval
                else:
                    # –ü–æ—Å–ª–µ 30 —Å–µ–∫—É–Ω–¥, –µ—Å–ª–∏ –∞–∫—Ç–æ—Ä –µ—â–µ —Ä–∞–±–æ—Ç–∞–µ—Ç, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—Ç–≤–µ—Ç —Å —Ç–µ–∫—É—â–∏–º–∏ –¥–∞–Ω–Ω—ã–º–∏
                    try:
                        dataset_id = run_status.get("defaultDatasetId")
                        if dataset_id:
                            items = await fetch_items(dataset_id, limit=run_input["resultsLimit"])
                            if len(items) > 0:  # –ï—Å–ª–∏ –µ—Å—Ç—å –¥–∞–Ω–Ω—ã–µ, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∏—Ö
                                log.info(f"üìä –†–∞–Ω–Ω–∏–π –≤–æ–∑–≤—Ä–∞—Ç —Å {len(items)} —ç–ª–µ–º–µ–Ω—Ç–∞–º–∏ –¥–ª—è {username}")

                                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ –ª–æ–∫–∞–ª—å–Ω–æ
                                run_dir = Path("data") / run_id
                                run_dir.mkdir(parents=True, exist_ok=True)

                                user_meta = {
                                    "user_id": user_identifier,
                                    "username": username,
                                    "instagram_url": clean_url,
                                    "created_at": datetime.datetime.now().isoformat(),
                                    "async_request": True,
                                    "status": "data_ready"
                                }
                                (run_dir / "user_meta.json").write_text(json.dumps(user_meta, ensure_ascii=False, indent=2), encoding="utf-8")
                                (run_dir / "posts.json").write_text(json.dumps(items, ensure_ascii=False, indent=2), encoding="utf-8")

                                # –ó–∞–ø—É—Å–∫–∞–µ–º –∑–∞–≥—Ä—É–∑–∫—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ —Ñ–æ–Ω–µ
                                images_dir = run_dir / "images"
                                background_tasks.add_task(download_photos_async, items, images_dir, run_id, username)

                                return {
                                    "success": True,
                                    "runId": run_id,
                                    "username": username,
                                    "url": clean_url,
                                    "message": f"‚úÖ –î–∞–Ω–Ω—ã–µ –ø–æ–ª—É—á–µ–Ω—ã! –ü–æ–ª—É—á–µ–Ω–æ {len(items)} —ç–ª–µ–º–µ–Ω—Ç–æ–≤. –ü–∞—Ä—Å–∏–Ω–≥ –ø—Ä–æ–¥–æ–ª–∂–∞–µ—Ç—Å—è –≤ —Ñ–æ–Ω–µ.",
                                    "data": items,
                                    "status": "data_ready",
                                    "stats": {
                                        "total_items": len(items),
                                        "profile_data": len([item for item in items if item.get("username")]),
                                        "processing_time_seconds": elapsed_time,
                                        "images_status": "loading"
                                    }
                                }
                    except Exception as data_error:
                        log.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ: {data_error}")

                    # –ï—Å–ª–∏ –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö –∏–ª–∏ –æ—à–∏–±–∫–∞, –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º –∂–¥–∞—Ç—å
                    await asyncio.sleep(check_interval)
                    elapsed_time += check_interval

            else:
                raise HTTPException(500, f"–ù–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–π —Å—Ç–∞—Ç—É—Å –∞–∫—Ç–æ—Ä–∞: {status}")

        # –ï—Å–ª–∏ –Ω–µ –∑–∞–≤–µ—Ä—à–∏–ª–∏—Å—å –∑–∞ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω–æ–µ –≤—Ä–µ–º—è, –Ω–æ –µ—Å—Ç—å run_id, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–∏ –≤ —Ñ–æ–Ω–µ
        log.info(f"‚è∞ –ü–∞—Ä—Å–∏–Ω–≥ –Ω–µ –∑–∞–≤–µ—Ä—à–∏–ª—Å—è –∑–∞ {max_wait_time}—Å, –Ω–æ –ø—Ä–æ–¥–æ–ª–∂–∞–µ—Ç—Å—è –≤ —Ñ–æ–Ω–µ –¥–ª—è {run_id}")
        return {
            "success": True,
            "runId": run_id,
            "username": username,
            "url": clean_url,
            "message": f"üîÑ –ü–∞—Ä—Å–∏–Ω–≥ –∑–∞–ø—É—â–µ–Ω –∏ –ø—Ä–æ–¥–æ–ª–∂–∞–µ—Ç—Å—è –≤ —Ñ–æ–Ω–µ. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Å—Ç–∞—Ç—É—Å —á–µ—Ä–µ–∑ –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–∏–Ω—É—Ç.",
            "data": [],
            "status": "running",
            "stats": {
                "total_items": 0,
                "profile_data": 0,
                "processing_time_seconds": elapsed_time,
                "images_status": "pending"
            }
        }

    except Exception as e:
        log.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ start_scrape –¥–ª—è {username}: {e}")
        # –ï—Å–ª–∏ —É –Ω–∞—Å –µ—Å—Ç—å run_id, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –Ω–µ—É–¥–∞—á–µ
        if 'run_id' in locals():
            return {
                "success": False,
                "runId": run_id,
                "username": username,
                "url": clean_url,
                "message": f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ: {str(e)}",
                "data": [],
                "status": "error",
                "stats": {
                    "total_items": 0,
                    "profile_data": 0,
                    "processing_time_seconds": 0,
                    "images_status": "error"
                }
            }

        # –ï—Å–ª–∏ –Ω–µ—Ç run_id –∏–ª–∏ –¥—Ä—É–≥–∞—è –æ—à–∏–±–∫–∞, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—É—é –æ—à–∏–±–∫—É
        raise HTTPException(500, f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ –ø–∞—Ä—Å–∏–Ω–≥–∞: {str(e)}")




async def download_photos_async(items, images_dir, run_id, username):
    """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–π –≤ —Ñ–æ–Ω–µ —Å –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ–º —Å—Ç–∞—Ç—É—Å–∞"""
    try:
        log.info(f"üöÄ –ù–∞—á–∏–Ω–∞–µ–º –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—É—é –∑–∞–≥—Ä—É–∑–∫—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–ª—è {run_id}")

        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å –≤ user_meta.json
        run_dir = Path("data") / run_id
        user_meta_path = run_dir / "user_meta.json"

        if user_meta_path.exists():
            with open(user_meta_path, 'r', encoding='utf-8') as f:
                user_meta = json.load(f)

            user_meta["status"] = "images_loading"
            user_meta["images_started_at"] = datetime.datetime.now().isoformat()

            with open(user_meta_path, 'w', encoding='utf-8') as f:
                json.dump(user_meta, f, ensure_ascii=False, indent=2)

        # –ó–∞–ø—É—Å–∫–∞–µ–º –∑–∞–≥—Ä—É–∑–∫—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
        from app.services.downloader import download_photos
        download_photos(items, images_dir)

        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å –ø–æ—Å–ª–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è
        if user_meta_path.exists():
            with open(user_meta_path, 'r', encoding='utf-8') as f:
                user_meta = json.load(f)

            user_meta["status"] = "images_ready"
            user_meta["images_finished_at"] = datetime.datetime.now().isoformat()

            # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
            images_count = 0
            if images_dir.exists():
                for img_file in images_dir.glob("*.jpg"):
                    if not img_file.name.endswith("_placeholder.jpg"):
                        images_count += 1
                for img_file in images_dir.glob("*.jpeg"):
                    if not img_file.name.endswith("_placeholder.jpeg"):
                        images_count += 1
                for img_file in images_dir.glob("*.png"):
                    if not img_file.name.endswith("_placeholder.png"):
                        images_count += 1

            user_meta["images_count"] = images_count

            with open(user_meta_path, 'w', encoding='utf-8') as f:
                json.dump(user_meta, f, ensure_ascii=False, indent=2)

        log.info(f"‚úÖ –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∑–∞–≥—Ä—É–∂–µ–Ω—ã –¥–ª—è {run_id} ({images_count} —Ñ–∞–π–ª–æ–≤)")

    except Exception as e:
        log.error(f"‚ùå –û—à–∏–±–∫–∞ –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–π –∑–∞–≥—Ä—É–∑–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–ª—è {run_id}: {e}")

        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å —Å –æ—à–∏–±–∫–æ–π
        try:
            run_dir = Path("data") / run_id
            user_meta_path = run_dir / "user_meta.json"

            if user_meta_path.exists():
                with open(user_meta_path, 'r', encoding='utf-8') as f:
                    user_meta = json.load(f)

                user_meta["status"] = "images_error"
                user_meta["images_error"] = str(e)
                user_meta["images_finished_at"] = datetime.datetime.now().isoformat()

                with open(user_meta_path, 'w', encoding='utf-8') as f:
                    json.dump(user_meta, f, ensure_ascii=False, indent=2)
        except Exception as meta_error:
            log.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Å—Ç–∞—Ç—É—Å–∞: {meta_error}")


@app.get("/scrape-status")
async def get_scrape_status(run_id: str):
    """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Å—Ç–∞—Ç—É—Å –ø–∞—Ä—Å–∏–Ω–≥–∞ –∏ –∑–∞–≥—Ä—É–∑–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π"""
    try:
        run_dir = Path("data") / run_id

        if not run_dir.exists():
            raise HTTPException(404, "–ü–∞—Ä—Å–∏–Ω–≥ —Å —Ç–∞–∫–∏–º run_id –Ω–µ –Ω–∞–π–¥–µ–Ω")

        # –ß–∏—Ç–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        user_meta_path = run_dir / "user_meta.json"
        if not user_meta_path.exists():
            raise HTTPException(404, "–ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")

        with open(user_meta_path, 'r', encoding='utf-8') as f:
            user_meta = json.load(f)

        # –ß–∏—Ç–∞–µ–º –ø–æ—Å—Ç—ã
        posts_path = run_dir / "posts.json"
        items = []
        if posts_path.exists():
            with open(posts_path, 'r', encoding='utf-8') as f:
                items = json.load(f)

        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        images_count = 0
        images_dir = run_dir / "images"
        if images_dir.exists():
            for img_file in images_dir.glob("*.jpg"):
                if not img_file.name.endswith("_placeholder.jpg"):
                    images_count += 1
            for img_file in images_dir.glob("*.jpeg"):
                if not img_file.name.endswith("_placeholder.jpeg"):
                    images_count += 1
            for img_file in images_dir.glob("*.png"):
                if not img_file.name.endswith("_placeholder.png"):
                    images_count += 1

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –æ–±—â–∏–π —Å—Ç–∞—Ç—É—Å
        status = user_meta.get("status", "unknown")
        if status == "data_ready" and user_meta.get("images_finished_at"):
            overall_status = "completed"
        elif status == "images_ready":
            overall_status = "completed"
        elif status == "images_loading":
            overall_status = "images_loading"
        elif status == "images_error":
            overall_status = "error"
        else:
            overall_status = status

        return {
            "success": True,
            "run_id": run_id,
            "status": overall_status,
            "details": {
                "data_status": status,
                "images_count": images_count,
                "total_posts": len(items),
                "created_at": user_meta.get("created_at"),
                "images_started_at": user_meta.get("images_started_at"),
                "images_finished_at": user_meta.get("images_finished_at"),
                "images_error": user_meta.get("images_error")
            }
        }

    except HTTPException:
        raise
    except Exception as e:
        log.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç—É—Å–∞: {e}")
        raise HTTPException(500, str(e))


@app.get("/get-images")
async def get_images(run_id: str):
    """
    –ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–ª—è run_id
    
    Args:
        run_id: ID –∑–∞–ø—É—Å–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞
    """
    try:
        run_dir = Path("data") / run_id / "images"
        
        if not run_dir.exists():
            raise HTTPException(404, "–ü–∞–ø–∫–∞ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
        
        # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (–∫—Ä–æ–º–µ placeholder)
        images = []
        for img_file in sorted(run_dir.glob("*.jpg")):
            if not img_file.name.endswith("_placeholder.jpg"):
                images.append(img_file.name)
        
        for img_file in sorted(run_dir.glob("*.jpeg")):
            if not img_file.name.endswith("_placeholder.jpeg"):
                images.append(img_file.name)
        
        for img_file in sorted(run_dir.glob("*.png")):
            if not img_file.name.endswith("_placeholder.png"):
                images.append(img_file.name)
        
        log.info(f"üì∏ –ù–∞–π–¥–µ–Ω–æ {len(images)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–ª—è run_id={run_id}")
        
        return {
            "success": True,
            "run_id": run_id,
            "total_images": len(images),
            "images": images
        }
        
    except HTTPException:
        raise
    except Exception as e:
        log.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å–ø–∏—Å–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {e}")
        raise HTTPException(500, str(e))


@app.get("/image/{run_id}/{filename}")
async def get_image(run_id: str, filename: str):
    """
    –ü–æ–ª—É—á–∏—Ç—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
    
    Args:
        run_id: ID –∑–∞–ø—É—Å–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞
        filename: –ò–º—è —Ñ–∞–π–ª–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    """
    try:
        # –ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å: –ø—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ filename –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –ø—É—Ç–µ–π
        if "/" in filename or "\\" in filename or ".." in filename:
            raise HTTPException(400, "–ù–µ–¥–æ–ø—É—Å—Ç–∏–º–æ–µ –∏–º—è —Ñ–∞–π–ª–∞")
        
        image_path = Path("data") / run_id / "images" / filename
        
        if not image_path.exists():
            raise HTTPException(404, "–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
        
        return FileResponse(image_path)
        
    except HTTPException:
        raise
    except Exception as e:
        log.error(f"‚ùå –û—à–∏–±–∫–∞ –æ—Ç–¥–∞—á–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {e}")
        raise HTTPException(500, str(e))
